@techreport{hasegawajohnson1997factor,
 title={Factor Analysis of MRI-Derived Articulator Shapes},
 institution={NIH NIDCD (\$145,026)},
 series={Individual National Research Service Award},
 number={1 F32 DC000323},
 author={Mark Hasegawa-Johnson},
 year={1997--1999},
 grant={external},
 url={https://reporter.nih.gov/search/A6RtagBSbEGeJ5AATGiLlw/project-details/2522259}
 }

@techreport{hasegawajohnson1999factor,
 author={Mark Hasegawa-Johnson},
 title={Factor Analysis of the Tongue Shapes of Speech},
 institution={University of Illinois Research Board},
 number={7},
 year={1999--2000},
 url={https://speechtechnology.web.illinois.edu/factor-analysis-of-the-tongue-shapes-of-speech/},
 grant={internal},
 img={https://speechtechnology.web.illinois.edu/media/online/projects/adsagit-500x300.jpg}
 }

@techreport{hasegawajohnson2001immersive,
 author={Mark Hasegawa-Johnson},
 title={Immersive Headphone-free Virtual Reality Audio},
 institution={University of Illinois Research Board},
 number={23},
 year={2001--2002},
 url={https://speechtechnology.web.illinois.edu/immersive-headphone-free-virtual-reality-audio/},
 grant={internal},
 img={https://speechtechnology.web.illinois.edu/media/online/projects/capture1-500x300.jpg}
 }

@techreport{hasegawajohnson2002prosody,
 author={Mark Hasegawa-Johnson and Jennifer Cole},
 title={Prosody-Dependent Speech Recognition},
 institution={University of Illinois Critical Research Initiative},
 number={2},
 year={2002--2004},
 url={https://speechtechnology.web.illinois.edu/prosody-dependent-speech-recognition/},
 grant={internal},
 img={https://speechtechnology.web.illinois.edu/media/online/projects/prosodypeople-500x300.jpg}
 }

@techreport{hasegawahjohnson2002career,
 author={Mark Hasegawa-Johnson},
 title={CAREER: Landmark-Based Speech Recognition in Music and Speech Backgrounds},
 institution={NSF IIS Division of Information and Intelligent Systems (\$418,766)},
 number={01-32900},
 year={2002--2007},
 grant={external},
 url={https://www.nsf.gov/awardsearch/showAward?AWD_ID=0132900}
 }

@techreport{hasegawajohnson2002acoustic,
 author={Mark Hasegawa-Johnson},
 title={Acoustic Features for Phoneme Recognition},
 institution={Phonetact Incorporated (\$35,000)},
 number={2002.1.4},
 year={2002},
 url={https://speechtechnology.web.illinois.edu/acoustic-features-for-phoneme-recognition/},
 grant={external},
 img={https://speechtechnology.web.illinois.edu/media/online/projects/sample_infogram-500x300.jpg}
 }

@techreport{hasegawajohnson2002audiovisual,
 author={Mark Hasegawa-Johnson and Thomas S Huang},
 title={Audiovisual Speech Recognition: Data Collection and Feature Extraction in Automotive Environment},
 institution={Motorola Communications Center (\$100,000)},
 number={RPS 19},
 year={2002--2005},
 url={https://speechtechnology.web.illinois.edu/audiovisual-speech-recognition-data-collection-and-feature-extraction-in-automotive-environment/},
 grant={external},
 img={https://speechtechnology.web.illinois.edu/media/online/projects/inside-500x300.jpg}
 }

@techreport{zhu2002development,
 author={Weimo Zhu},
 title={Development and Validation of An E-diary System for Assessing Physical Activity and Travel Behaviors},
 institution={Robert Wood Johnson Foundation (\$100,000)},
 number={47334},
 year={2002--2004},
 grant={external},
 url={https://speechtechnology.web.illinois.edu/development-and-validation-of-an-e-diary-system-for-assessing-physical-activity-and-travel-behaviors/}
 }

@techreport{hasegawajohnsons2004prosodic,
 author={Mark Hasegawa-Johnson and Jennifer Cole and Chi-Lin Shih},
 title={Prosodic, Intonational, and Voice Quality Correlates of Disfluency},
 institution={NSF IIS Division of Information and Intelligent Systems (\$526,973)},
 number={04-14117},
 year={2004--2007},
 grant={external},
 url={https://www.nsf.gov/awardsearch/showAward?AWD_ID=0414117}
 }

@techreport{sproat2005automated,
 author={Richard Sproat and Chilin Shih and Mark Hasegawa-Johnson and Dan Roth and Kay Bock and
 Brian Ross},
 title={Automated Methods for Second-Language Fluency Assessment},
 number={3},
 institution={University of Illinois Critical Research Initiative},
 year={2005--2007},
 grant={internal},
 url={https://speechtechnology.web.illinois.edu/automatic-methods-for-second-language-fluency-assessment/}
 }

@techreport{hasegawajohnson2005audiovisual,
 author={Mark Hasegawa-Johnson and Adrienne Perlman and Thomas Huan and Jon Gunderson},
 title={Audiovisual Distinctive-Feature-Based Recognition of Dysarthric Speech},
 institution={NSF IIS Division of Information and Intelligent Systems (\$668,575)},
 number={05-34106},
 year={2005--2010},
 grant={external},
 url={https://www.nsf.gov/awardsearch/showAward?AWD_ID=0534106}
 }

@techreport{hasegawajohnson2006audiovisual,
 author={Mark Hasegawa-Johnson and Adrienne Perlman and Thomas S Huang and Jon Gunderson and
 Ken Watkin and Heejin Kim},
 title={Audiovisual Description and Recognition of Audible and Visible Dysarthric Phonology},
 institution={NIH NIDCD (\$388,651))},
 number={5R21 DC008090},
 year={2006--2009},
 url={https://speechtechnology.web.illinois.edu/audiovisual-description-and-recognition-of-audible-and-visible-dysarthric-phonology/},
 grant={external},
 img={https://speechtechnology.web.illinois.edu/media/online/projects/beckmanOH09_1-500x300.jpg}
 }

@techreport{hasegawajohnson2005rhythmic,
 author={Mark Hasegawa-Johnson},
 title={Rhythmic Organization of Durations for Automatic Speech Recognition},
 institution={UIUC Research Board},
 number={6},
 grant={internal},
 year={2005--2006}
 }

@techreport{huang2005audiovisual,
 author={Thomas S Huang and Mark Hasegawa-Johnson},
 title={Audiovisual Emotional Speech AVATAR},
 institution={Motorola Communications Center (\$100,000)},
 number={RPS 31},
 grant={external},
 year={2005--2007}
 }

@techreport{sproat2006fluency,
 author={Richard Sproat and J. Kathryn Bock and Brian Ross and Mark Hasegawa-Johnson and Chi-Lin Shih},
 title={{DHB:} An Interdisciplinary Study of the Dynamics of Second Language Fluency},
 institution={NSF IIS Division of Information and Intelligent Systems (\$710,781)},
 number={06-23805},
 year={2006--2010},
 grant={external},
 url={https://www.nsf.gov/awardsearch/showAward?AWD_ID=0623805}
 }

@techreport{espywilson2007collaborative,
 author={Jennifer Cole and Mark Hasegawa-Johnson},
 title={{RI}-Collaborative Research: Landmark-based robust speech recognition using prosody-guided models of speech variability},
 institution={NSF IIS Division of Information and Intelligent Systems (\$541,320)},
 number={07-03624},
 year={2007--2012},
 grant={external},
 url={https://www.nsf.gov/awardsearch/showAward?AWD_ID=0703624}
 }

@techreport{hasegawajohnson2008audio,
 author={Mark Hasegawa-Johnson and Thomas Huang and Dirk Bernhardt-Walther},
 title={{RI} Medium: Audio Diarization - Towards Comprehensive Description of Audio Events},
 institution={NSF IIS Division of Information and Intelligent Systems (\$249,864)},
 number={08-03219},
 year={2008--2010},
 grant={external},
 url={https://www.nsf.gov/awardsearch/showAward?AWD_ID=0803219}
 }


@techreport{hasegawajohnson2008fodava,
 author={Mark Hasegawa-Johnson and Camille Goudeseune and Hank Kaczmarski and Thomas Huang},
 title={{FODAVA}-Partner: Visualizing Audio for Anomaly Detection},
 institution={NSF CCF Division of Computing and Communication Foundations (\$793,857)},
 number={08-07329},
 year={2008--2013},
 url={https://speechtechnology.web.illinois.edu/fodava-partner-visualizing-audio-for-anomaly-detection/},
 grant={external},
 img={https://speechtechnology.web.illinois.edu/media/online/projects/milliphone-500x300.jpg}
 }

@techreport{beranek2009opportunistic,
 author={Richard Beraniuk and Volkan Cevher and Lydia Kavraki and Wotao Yin and John Benedetto and Rama Chellappa and Larry Davis and Tamer Basar and Mark Hasegawa-Johnson and Thomas Huang and Ronald Coifman and Lawrence Carin and Stanley Osher},
 title={Opportunistic Sensing for Object and Activity Recognition from Multi-Modal, Multi-Platform Data},
 institution={ARO MURI},
 number={W911NF-09-1-0383},
 year={2009--2014},
 url={https://speechtechnology.web.illinois.edu/opportunistic-sensing-for-object-and-activity-recognition-from-multi-modal-multi-platform-data/},
 grant={external},
 img={https://speechtechnology.web.illinois.edu/media/online/projects/seismic_audio_tagging-500x300.jpg}
 }

@techreport{hasegawajohnson2010multi,
 author={Mark Hasegawa-Johnson and Eiman Mustafawi},
 title={Multi-dialect phrase-based speech recognition and machine translation for {Qatari} broadcast TV},
 institution={QNRF Qatar National Research Fund (\$734,266)},
 number={NPRP 09-410-1-069},
 year={2010--2013},
 url={https://speechtechnology.web.illinois.edu/multi-dialect-phrase-based-speech-recognition-and-machine-translation-for-qatari-broadcast-tv/},
 grant={external},
 img={https://speechtechnology.web.illinois.edu/media/online/projects/qu_members_2013-06-16-500x300.jpg}
 }

@techreport{poole2010cdi,
 author={Marshall Poole and David Forsyth and Feniosky Pena-Mora and Mark Hasegawa-Johnson and
 Kenton McHenry and Peter Bajcsy},
 title={{CDI-Type II:} Collaborative Research: Groupscope: Instrumenting Research on Interaction Networks in Complex Social Contexts},
 institution={NSF BCS Division Of Behavioral and Cognitive Sci (\$1,697,482)},
 number={0941268},
 year={2010--2015},
 url={https://speechtechnology.web.illinois.edu/cdi-type-ii-collaborative-research-groupscope-instrumenting-research-on-interaction-networks-in-complex-social-contexts/},
 grant={external},
 img={https://speechtechnology.web.illinois.edu/media/online/projects/meeting2-500x300.jpg}
 }

@techreport{loucks2010speech,
 author={Torrey Loucks and Chilin Shih and Ryan Shosted and Mark Hasegawa-Johnson},
 title={Speech Production Research Initiative},
 institution={University of Illinois Graduate College Focal Point Program},
 year={2010--2011},
 number={2},
 url={https://speechtechnology.web.illinois.edu/speech-production-research-initiative/},
 grant={internal},
 img={https://speechtechnology.web.illinois.edu/media/online/projects/sprei_banner-500x300.jpg}
 }

@techreport{hasegawajohnson2011pseudo,
 author={Mark Hasegawa-Johnson and Laura DeThorne and Tracy Gunderson and Julie Hengst and Thomas Huang
 and Pat Malik},
 title={Pseudo-intelligent mediators (``Robo-Buddies'') to improve communication between students
 with and students without physical disabilities},
 number={1},
 institution={Illinois Innovation Initiative (In3)},
 grant={internal},
 year={2011--2015}
 }

@techreport{hengst2012social,
 author={Julie Hengst and Laura S. DeThorne and Ai Leen Choo and Mariana Aparacio Betancourt
 and Mark Hasegawa-Johnson and Karrie Karahalios and Paul Prior and Hedda Meadan-Kaplansky and
 David Gooler and Tracy Gunderson and Andrew Moss},
 title={Conversation Strategies for Students With and Students Without Physical Disabilities},
 institution={University of Illinois Graduate College Focal Point Program},
 number={3},
 year={2012--2013},
 grant={internal},
 url={kyhttp://go.illinois.edu/SABAC}
 }

@techreport{morrow2014collaborative,
 author={Daniel G Morrow and Mark Hasegawa-Johnson and Thomas Huang and William Schuh},
 institution={AHRQ Agency for Healthcare Research and Quality (\$299,602)},
 number={R21-HS022948},
 title={Collaborative Patient Portals: Computer-based Agents and Patients' Understanding of Numeric Health Information},
 year={2014--2016},
 url={https://speechtechnology.web.illinois.edu/collaborative-patient-portals-computer-based-agents-and-patients-understanding-of-numeric-health-information/},
 grant={external},
 img={https://speechtechnology.web.illinois.edu/media/online/projects/graphicdisplay-500x300.jpg}
 }

@techreport{hasegawajohnson2014family,
 author={Mark Hasegawa-Johnson and Hanady Mansour Ahmed and Eiman Mustafawi and Haitham El-Bashir},
 institution={QNRF Qatar National Research Fund (\$858,827)},
 number={NPRP 7-766-1-140},
 title={The Family as the Unit of Intervention for Speech-Generating Augmentative/Assistive Communication},
 year={2014--2018},
 url={https://speechtechnology.web.illinois.edu/the-family-as-the-unit-of-intervention-for-speech-generating-augmentative-assistive-communication/},
 grant={external},
 img={https://speechtechnology.web.illinois.edu/media/online/projects/protoscreens-500x300.jpg}
 }

@techreport{yang2015speech2vec,
 title={Speech2Vec Speech-Based Semantic Vectors},
 author={Mark Hasegawa-Johnson and Gregg Wilensky and Xuesong Yang},
 institution={Adobe Research (\$25,000))},
 number={2015.w.uiuc},
 url={https://speechtechnology.web.illinois.edu/speech2vec-speech-based-semantic-vectors/},
 grant={external},
 year={2015--2016}
 }
 
@techreport{zhang2015vocal,
 title={Speech Resynthesis for Vocal Style Modification},
 author= {Mark Hasegawa-Johnson and Gautham Mysore and Yang Zhang},
 institution={Adobe Research (\$25,000)},
 number={2015.m.uiuc},
 url={https://speechtechnology.web.illinois.edu/speech-resynthesis-for-vocal-style-modification/},
 grant={external},
 year={2015--2017}
 }
 
@techreport{ren2015capturing,
 author={Jia Chen Ren and Lawrence Angrave and Mark Hasegawa-Johnson},
 institution={Illinois Learning Sciences Design Initiative (ILSDI), University of Illinois},
 title={Capturing; Transcribing; Searching; Analyzing; Adaptive: Learning in a curated classroom},
 year={2015--2016},
 number={5},
 url={https://speechtechnology.web.illinois.edu/capturing-transcribing-searching-analyzing-adaptive-learning-in-a-curated-classroom/},
 grant={internal},
 img={https://speechtechnology.web.illinois.edu/media/online/projects/firstpass400-500x300.jpg}
 }

@techreport{chen2015mismatched,
 author={Nancy Chen and Mark Hasegawa-Johnson},
 institution={Institute for Infocomm Research (I$^2$R), Agency for Science, Technology, Advancement and Research (ASTAR) (\$399,999)},
 address={Singapore},
 number={36},
 title={Mismatched Crowdsourcing for 80-Language Speech Recognition},
 grant={external},
 year={2015--2017}
 }

@techreport{hasegawajohnson2015noisy,
 author={Mark Hasegawa-Johnson and Nancy Chen and Boon Pang Lim},
 institution={Advanced Digital Sciences Center (ADSC)},
 address={Singapore},
 title={Noisy Channel Models for Massively Multilingual Automatic Speech Recognition},
 year={2015--2017},
 number={9},
 url={https://speechtechnology.web.illinois.edu/noisy-channel-models-for-massively-multilingual-automatic-speech-recognition/},
 grant={internal},
 img={https://speechtechnology.web.illinois.edu/media/online/projects/mismatch-500x300.jpg}
 }

@techreport{hasegawajohnson2015eager,
 author={Mark Hasegawa-Johnson and Lav Varshney and Preethi Jyothi},
 institution={NSF IIS Division of Information and Intelligent Systems (\$150,000)},
 title={{EAGER:} Matching Non-Native Transcribers to the Distinctive Features of the Language Transcribed},
 number={1550145},
 year={2015--2018},
 url={https://speechtechnology.web.illinois.edu/eager-matching-non-native-transcribers-to-the-distinctive-features-of-the-language-transcribed/},
 grant={external},
 img={https://speechtechnology.web.illinois.edu/media/online/projects/binarylabeling-500x300.jpg}
 }

@techreport{kirchhoff2015languagenet,
 author={Mark Hasegawa-Johnson},
 institution={DARPA LO-REsource Languages for Emergent Incidents (LORELEI) (\$408,325)},
 number={HR0011-15-2-0043},
 title={LanguageNet: Transfer Learning Across a Language Similarity Network},
 year={2015--2019},
 url={https://speechtechnology.web.illinois.edu/languagenet-transfer-learning-across-a-language-similarity-network/},
 grant={external},
 img={https://speechtechnology.web.illinois.edu/media/online/projects/LangNet-500x300.jpg}
 }

@techreport{morrow2016interactive,
 title={Interactive Technology Support for Patient Medication Self-Management},
 author={Dan Morrow and Suma Pallathadka Bhat and Mark Hasegawa-Johnson and Thomas Huang and
 James Graumlich and Ann Willemsen-Dunlap and Don Halpin},
 institution={Jump ARCHES},
 number={4},
 year={2016--2018},
 grant={internal},
 url={https://newsroom.osfhealthcare.org/2017-jump-arches-endowment-grant-recipients-announced/}
 }
 
@techreport{dehak2019collaborative,
 author={Najim Dehak and Mark Hasegawa-Johnson},
 institution={NSF IIS Division of Information and Intelligent Systems (\$259,765)},
 number={19-10319},
 title={{RI}: Small: Collaborative Research: Automatic Creation of New Phone Inventories},
 year={2019--2022},
 grant={external},
 url={https://www.nsf.gov/awardsearch/showAward?AWD_ID=1910319}
 }

@techreport{mcelwain2020early,
 author={Nancy McElwain and Susan Caldecott-Johnson and Mark Hasegawa-Johnson and Siraj Siddiqi
 and Romit Roy Choudhury},
 title={Early Detection Of Developmental Disorders Via A Remote Sensing Platform},
 year={2020--2021},
 number={6},
 institution={Jump ARCHES},
 url={https://littlebeats.hdfs.illinois.edu/},
 grant={internal},
 number={7}
 }
 
@techreport{karahalios2020early,
 author={Karrie Karahalios and Siraj Siddiqi and David Forsyth and Mark Hasegawa-Johnson
 and Hedda Meadan},
 title={Visualizations Of Social Communication Behavior Of Children With Autism},
 year={2020--2021},
 institution={Jump ARCHES},
 number={5},
 grant={internal},
 url={https://csbs.research.illinois.edu/research-support/jump-arches-grants/jump-arches-awarded-proposals-in-the-social-and-behavioral-sciences/}
 }
 
@techreport{morrow2020using,
 author={Mark Hasegawa-Johnson and Suma Bhat and Dan Morrow and James Graumlich},
 title={Using Conversational Agents To Support Older Adult Learning For Health},
 number={4},
 institution={UIUC College of Education Technology Innovation in Educational Research and Design},
 year={2020--2021},
 grant={internal},
 url={https://tier-ed.education.illinois.edu/projects-and-research}
 }
 
@techreport{hasegawajohnson2020deep,
 author={Changdong Yoo and Mark Hasegawa-Johnson},
 institution={IITP Institute for Information \& Communications Technology Promotion (\$500,000)},
 address={Korea},
 title={Deep F-measure Maximization for Fairness in Speech Understanding},
 year={2020--2025},
 grant={external},
 number={507691}
 }

@techreport{ahuja2020adding,
 author={Narendra Ahuja and Mark Hasegawa-Johnson and David Beiser and David Chestek},
 institution={C3.ai Digital Transformation Institute (\$498,998)},
 title={Adding Audio-Visual Cues to Signs and Symptoms for Triaging Suspected or Diagnosed COVID-19 Patients},
 number={23},
 year={2020--2022},
 grant={external},
 url={https://c3.ai/c3-ai-digital-transformation-institute-announces-covid-19-awards}
 }

@techreport{juneja2021virtual,
 author={Amit Juneja and Mark Hasegawa-Johnson and James Mireles},
 title={STTR Virtual Reality Visualization of Complex and Unstructured Data and Relationships},
 institution={USAF United States Air Force (\$49,995)},
 number={FA864922P0047},
 grant={external},
 year={2021--2022}
 }

@techreport{hasegawajohnson2022picsart,
 author={Mark Hasegawa-Johnson},
 title={Unrestricted gift},
 institution={Picsart Corporation (\$100,000)},
 year={2022--2025},
 number={638245},
 grant={external}
 }
 
@techreport{mcelwain2022continuous,
 title={Continuous Capture of Infant Feeding, Motor Activity, and Sleep Biorhythms via an Infant Wearable Platform and Machine Learning Approaches},
 author={Nancy McElwain and Mark Hasegawa-Johnson and Dominika M Pindus and Bashima Islam and
 Charles Davies and Maria Davila},
 year={2022--2023},
 institution={University of Illinois Personalized Nutrition Initiative},
 number={2},
 url={https://littlebeats.hdfs.illinois.edu/},
 grant={internal},
 img={https://speechtechnology.web.illinois.edu/media/online/projects/littlebeats-500x300.jpg}
 }
 
@techreport{hasegawajohnson2022fai,
 author={Mark Hasegawa-Johnson and Zsuzsanna Fagyal and Najim Dehak and Piotr Zelasko and Laureano Moro-Velazquez},
 institution={NSF IIS Division of Information and Intelligent Systems (\$500,000)},
 title={{FAI}: A New Paradigm for the Evaluation and Training of Inclusive Automatic Speech Recognition},
 number={2147350},
 year={2022--2026},
 url={https://www.nsf.gov/awardsearch/showAward?AWD_ID=2147350&HistoricalAwards=false},
 grant={external},
 img={https://speechtechnology.web.illinois.edu/media/online/projects/inclusive_speech_recognition-500x300.jpg}
 }

@techreport{juneja2022virtual,
 author={Amit Juneja and Mark Hasegawa-Johnson and James Mireles},
 title={STTR Phase II Proposal F2-15825 Virtual Reality Visualization of Complex and Unstructured Data andRelationships},
 institution={USAF United States Air Force (\$749,952)},
 number={F2-15825},
 grant={external},
 year={2022--2023}
 }

@techreport{hasegawajohnson2022nova,
 author={Mark Hasegawa-Johnson and Heejin Kim and Clarion Mendes and Meg Dickinson and Erik Hege and Chris Zwilling},
 title={Speech Accessibility Project},
 institution={AI Accessibility Coalition (Amazon, Apple, Google, Meta and Microsoft)},
 year={2022--2025},
 number={548308-392030},
 url={https://speechaccessibilityproject.beckman.illinois.edu/},
 grant={external},
 img={https://speechtechnology.web.illinois.edu/media/online/projects/speech_accessibility_project-500x300.jpg}
}

@techreport{govindaraju2023ai4exceptional,
 author={Venu Govindaraju and Jinjun Xiong and Srirangaraj Setlur and Pamela Hadley and Julie Kientz and David Feil-Seifer and Brian Graham and Megan-Brette Hamilton and Anil K Jain and Ye Jia and Jennifer Taps Richard and Tracy A Sawicki and Alison Hendricks and Ifeoma Nwogu and Letitia Thomas and Christine Wang and Wenyao Xu and Maneesh Agrawala and Diego Aguirre and Changyou Chen and Karthik Dantu and Mark Frank and Nick Haber and Mark Hasegawa-Johnson and Yun Huang and Heng Ji and Windi Krok and Hedda Meadan-Kaplansky and Carol Miller and Abbie Olszewski and Mari Ostendorf and Alexander Rush and Humphrey Shi and Hariharan Subramonyam and Nigel Ward and Junsong Yuan and Shaofeng Zou},
 institution={NSF DRL Division Of Research On Learning (\$20,000,000)},
 number={2229873},
 title={AI Institute for Transforming Education for Children with Speech and Language Processing Challenges},
 url={https://www.buffalo.edu/ai4exceptionaled.html},
 img={https://speechtechnology.web.illinois.edu/media/online/projects/ai4exceptionaled_slide-500x300.jpg},
 grant={external},
 year={2023--2028}
 }


@techreport{mcelwain2024validation,
title={Validation of a Virtual Still Face Procedure and Deep Learning Algorithms to Assess Infant Emotion Regulation and Infant-Caregiver Interactions in the Wild},
author={Nancy McElwain and Mark Hasegawa-Johnson and Bashima Islam and Brandon Meline and Maria Davila and Keri Heilman},
institution={National Institute on Drug Abuse (\$1,280,875)},
number={1 R01 DA059422-01},
year={2024--2029},
 grant={external},
url={https://reporter.nih.gov/project-details/10777825}
}

@techreport{mcelwain2024nddk,
author={Nancy McElwain and Mark Hasegawa-Johnson and Bashima Islam},
title={Automated Assessment of Infant Sleep/Wake States, Physical Activity, and Household Noise Using a Multimodal Wearable Device and Deep Learning Models},
url={https://taggs.hhs.gov/Detail/AwardDetail?arg_AwardNum=R01DK138866&arg_ProgOfficeCode=119},
number={1 R01 DK138866-01},
institution={National Institute on Diabetes and Digestive and Kidney Diseases (\$606,042)},
 grant={external},
year={2024--2029}
}

@techreport{waitda2025,
author={Inha University and Ewha Women's University and University of Illinois at Urbana-Champaign},
title={Workshop on Assistive and Inclusive Technology for Digital Accessibility},
year={2025},
month={2},
url={https://speechtechnology.web.illinois.edu/waitda/index.html}
}